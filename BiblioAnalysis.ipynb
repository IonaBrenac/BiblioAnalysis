{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiblioAnalysis_Main\n",
    "\n",
    "### Version: 0.0.0\n",
    "\n",
    "### Aims\n",
    "- This jupyter notebook results from the use analysis of BiblioTools2jupyter notebook and a new implementation of the following parts:\n",
    "    - Parsing: replaced and tested \n",
    "    - Corpus description: replaced and tested\n",
    "    - Filtering: replaced and tested, integrating the \"EXCLUSION\" mode and the recursive filtering\n",
    "    - Cooccurrence analysis : replaced and tested, integrating graph plot and countries GPS coordinates\n",
    "    - Coupling analyis : replaced and tested\n",
    "    \n",
    "### Created modules in the package BiblioAnalysis_Utils\n",
    "    - BiblioCooc.py\n",
    "    - BiblioCoupling.py\n",
    "    - BiblioDescription.py\n",
    "    - BiblioFilter.py    \n",
    "    - BiblioGeneralGlobals.py\n",
    "    - BiblioGlobals.py\n",
    "    - BiblioGraphPlot.py\n",
    "    - BiblioGui.py.py\n",
    "    - BiblioNltk.py\n",
    "    - BiblioParsingGlobals.py\n",
    "    - BiblioParsingScopus.py\n",
    "    - BiblioParsingUtils.py\n",
    "    - BiblioParsingWos.py\n",
    "    - BibloRefs.py\n",
    "    - BiblioTempDev.py\n",
    "\n",
    "### BiblioTool3.2 source\n",
    "http://www.sebastian-grauwin.com/bibliomaps/download.html \n",
    "\n",
    "### List of initial Python packages extracted from  BiblioTool3.2\n",
    "- biblio_parser.py\t⇒ pre-processes WOS / Scopus data files,\n",
    "- corpus_description.py\t⇒ performs a frequency analysis of the items in corpus,\n",
    "- filter.py\t⇒ filters the corpus according to a range of potential queries but still too specific\n",
    "- biblio_coupling.py\t⇒ performs a BC anaysis of the corpus,\n",
    "- cooc_graphs.py\t⇒ produces various co-occurrence graphs based on the corpus (call parameters changed)\n",
    "\n",
    "### Specifically required list of pip install \n",
    "(to be integrated in the setup.py of BiblioAnalysis_Utils)\n",
    "- !pip3 install squarify \n",
    "- !pip3 install inquirer\n",
    "- !pip3 install python-louvain\n",
    "- !pip3 install pyvis\n",
    "\n",
    "### Specifically required nltk downloads \n",
    "(integrated in BiblioNltk.py of BiblioAnalysis_Utils)\n",
    "- import nltk\n",
    "    - nltk.download('punkt')\n",
    "    - nltk.download('averaged_perceptron_tagger')\n",
    "    - nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary instructions\n",
    "#### These actions will be interactively performed in the next version of the Jupyter notebook\n",
    "- Create the 'BiblioAnalysis_Files/' folder in your 'Users/' folder\n",
    "<br>\n",
    "<br>\n",
    "- Create in this 'BiblioAnalysis_Files/' folder, the 'Configuration_Files/' folder\n",
    "<br>\n",
    "- Store the configuration files (config_filter.json) a the 'Configuration_Files/' folder that are:\n",
    "    - 'config_filter.json' used for the filtering of a corpus\n",
    "    - 'congig_temporal.json'used for the temporal development of item values in a set of annual coupuses \n",
    "<br>\n",
    "<br>\n",
    "- Create, in the 'Configuration_Files/' folder, your additional_files folder to be named 'Selection_Files/' \n",
    "<br>\n",
    "- Store your files (free names) of selected item values in this additional_files folder together with:\n",
    "    - 'TempDevK_full.txt' used to select the words to search in the description files of the corpuses for the temporal development of item values in the set of annual coupuses\n",
    "<br>\n",
    "<br>\n",
    "- Create, in the 'BiblioAnalysis_Files/' folder, your project folder\n",
    "<br>\n",
    "- Create the 'rawdata/' folder in your project folder\n",
    "<br>\n",
    "- Store your corpus file (either wos or scopus extraction) in the 'rawdata/' folder of your project folder\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I- User environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import platform\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Set the venv use status\n",
    "venv = False\n",
    "print('Virtual environment: ', venv)\n",
    "\n",
    "# Get the information of current operating system\n",
    "os_name = platform.uname().system\n",
    "print('Operating system:    ', os_name)\n",
    "if os_name=='Darwin':bau.add_site_packages_path(venv)\n",
    "\n",
    "# User identification\n",
    "user_root = Path.home()\n",
    "user_id =  str(user_root)[str(user_root).rfind('/')+1:]\n",
    "print('User:                ', user_id)\n",
    "expert =  False\n",
    "\n",
    "# Getting the corpuses folder\n",
    " # Setting the GUI titles\n",
    "gui_titles = {'main':   'Corpuses folder selection window',\n",
    "              'result': 'Selected folder'}\n",
    "gui_buttons = ['SELECTION','HELP']\n",
    "\n",
    "corpuses_folder = bau.select_folder_gui_new(user_root, gui_titles, gui_buttons, bau.GUI_DISP)\n",
    "print('\\nCorpuses folder:', corpuses_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Single year corpus analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &emsp;&emsp;II-1 Selection of the corpus file for BiblioAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "## Selection of corpus file\n",
    "corpusfiles_list = os.listdir(corpuses_folder)\n",
    "corpusfiles_list.sort()\n",
    "print('Please select the corpus via the tk window')\n",
    "myprojectname = bau.Select_multi_items(corpusfiles_list,'single',2)[0]+'/'\n",
    "project_folder = corpuses_folder /Path(myprojectname)\n",
    "database_type = input('Corpus file type (scopus, wos - default: \"wos\")? ')\n",
    "if database_type =='': database_type = 'wos' \n",
    "\n",
    "rep_utils =''\n",
    "if database_type =='scopus':\n",
    "     # Get the folder for the general files\n",
    "     # and specific files for scopus type database in this folder\n",
    "    if os_name=='Darwin':\n",
    "        rep_utils = os.path.abspath('BiblioAnalysis_RefFiles')        \n",
    "    else:\n",
    "        gui_titles = {'main':   'Folder selection window for categories files of scopus ',\n",
    "                      'result': 'Selected folder'}\n",
    "        gui_buttons = ['SELECTION','HELP']\n",
    "        rep_utils = bau.select_folder_gui_new(user_root, gui_titles, gui_buttons, bau.GUI_DISP)\n",
    "    scopus_cat_codes = bau.SCOPUS_CAT_CODES\n",
    "    scopus_journals_issn_cat = bau.SCOPUS_JOURNALS_ISSN_CAT\n",
    "    print('Folder for the categories files of scopus:', rep_utils)       \n",
    "    \n",
    "## Setting the  graph main heading\n",
    "digits_list = list(filter(str.isdigit, myprojectname))\n",
    "corpus_year = ''\n",
    "for i in range(len(digits_list)):corpus_year = corpus_year + digits_list[i]\n",
    "init = str(corpuses_folder).rfind(\"_\")+1\n",
    "corpus_state = str(corpuses_folder)[init:]\n",
    "main_heading = corpus_year + ' Corpus:' + corpus_state\n",
    "\n",
    "## Printing useful information\n",
    "#print('\\nSpecific-paths set for user: ', user_id)\n",
    "#print('Project folder:              ', project_folder)\n",
    "#print('Corpus year:                 ', corpus_year)\n",
    "#print('Corpus status:               ', corpus_state)\n",
    "#print('Project name:                ', myprojectname)\n",
    "#print('Corpus file type:            ', database_type)\n",
    "\n",
    "dict_print = {'Specific-paths set for user:': user_id,\n",
    "              'Project folder:': project_folder,\n",
    "              'Corpus year:': corpus_year,\n",
    "              'Corpus status:': corpus_state,\n",
    "              'Project name:': myprojectname,\n",
    "              'Corpus file type:':database_type}\n",
    "\n",
    "pad = 3\n",
    "max_len_str = max( [len(str(x)) for x in dict_print.values()]) + pad\n",
    "print('\\n')\n",
    "for key,val in dict_print.items():\n",
    "    print(key.ljust(max_len_str),val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &emsp;&emsp;II-2 Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries import\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "## Building the names of the useful folders\n",
    "\n",
    "    # Folder containing the wos or scopus file to process\n",
    "in_dir_parsing = project_folder / Path(bau.FOLDER_NAMES['rawdata'])\n",
    "\n",
    "    # Folder containing the output files of the data parsing \n",
    "out_dir_parsing = project_folder / Path(bau.FOLDER_NAMES['parsing'])\n",
    "if not os.path.exists(out_dir_parsing):\n",
    "    os.mkdir(out_dir_parsing)\n",
    "\n",
    "## Running function biblio_parser\n",
    "parser_done = input(\"Parsing available (y/n)? \")\n",
    "if parser_done == \"n\":\n",
    "     # Setting the specific affiliations filter (default = None)\n",
    "    second_inst = input(\"Secondary institutions to be parsed (y/n)? \")\n",
    "    if second_inst=='y' : \n",
    "        inst_filter_dic= {'secondary_inst': ['LITEN', 'INES'],\n",
    "                          'country': 'France'} \n",
    "    else:\n",
    "        inst_filter_dic = None\n",
    "    bau.biblio_parser(in_dir_parsing, out_dir_parsing, database_type, expert, rep_utils, inst_filter_dic) \n",
    "    with open(Path(out_dir_parsing) / Path('failed.json'), 'r') as failed_json:\n",
    "            data_failed=failed_json.read()\n",
    "    dic_failed = json.loads(data_failed)\n",
    "    articles_number = dic_failed[\"number of article\"]\n",
    "    print(\"Parsing processed on full corpus\")\n",
    "    print(\"\\n\\nSuccess rates\")\n",
    "    del dic_failed['number of article']\n",
    "    for item, value in dic_failed.items():\n",
    "        print(f'    {item}: {value[\"success (%)\"]:.2f}%')\n",
    "else:\n",
    "    parser_filt = input(\"Parsing available without rawdata -from filtering- (y/n)? \")\n",
    "    if parser_filt == \"n\":        \n",
    "        with open(Path(out_dir_parsing) / Path('failed.json'), 'r') as failed_json:\n",
    "            data_failed=failed_json.read()\n",
    "        dic_failed = json.loads(data_failed)\n",
    "        articles_number = dic_failed[\"number of article\"]\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Parsing available from full corpus\")\n",
    "        print(\"\\n\\nSuccess rates\")\n",
    "        del dic_failed['number of article']\n",
    "        for item, value in dic_failed.items():\n",
    "            print(f'    {item}: {value[\"success (%)\"]:.2f}%')\n",
    "    else:\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Parsing available from filtered corpus without rawdata\")\n",
    "        file = project_folder /Path('parsing/' + 'articles.dat')\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines()\n",
    "        articles_number = len(lines)\n",
    "\n",
    "print(\"\\n\\nCorpus parsing saved in folder:\\n\", str(out_dir_parsing))\n",
    "print('\\nNumber of articles in the corpus : ', articles_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  &emsp;&emsp;II-2.1 Data parsing / Corpus description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries import\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "## Building the names of the useful folders\n",
    "\n",
    "    # Folder containing the wos or scopus parsed files\n",
    "in_dir_corpus = out_dir_parsing\n",
    "\n",
    "    # Folder containing the wos or scopus parsed and analysed files\n",
    "out_dir_corpus = project_folder / Path(bau.FOLDER_NAMES['description'])\n",
    "if not os.path.exists(out_dir_corpus):\n",
    "    os.mkdir(out_dir_corpus)    \n",
    "\n",
    "## Running describe_corpus\n",
    "description_done = input(\"Description available (y/n)? \")\n",
    "#clear_output(wait=True)\n",
    "if description_done == \"n\":\n",
    "    verbose = False\n",
    "    bau.describe_corpus(in_dir_corpus, out_dir_corpus, database_type, verbose)\n",
    "    print(\"Corpus description saved in folder:\", str(out_dir_corpus))\n",
    "else:\n",
    "    print(\"Corpus description available in folder:\", str(out_dir_corpus))\n",
    "\n",
    "# Building the name of file for histogram plot of an item\n",
    "fullpath_distrib_item = out_dir_corpus / Path(bau.DISTRIBS_ITEM_FILE)\n",
    "\n",
    "## Running plot of treemap, scatter plot and histogram for a selected item_treemap\n",
    "do_treemap = input(\"Treemap for an item of the corpus description (y/n)? \")\n",
    "if do_treemap == 'y':\n",
    "    renew_treemap = 'y'\n",
    "    while renew_treemap == 'y' :\n",
    "        print(\"Choose the item for treemap in the tk window\")\n",
    "        item_treemap = bau.item_selection()\n",
    "        fullpath_file_treemap = out_dir_corpus / Path('freq_'+ item_treemap +'.dat')\n",
    "        print(\"Item selected:\",item_treemap)\n",
    "        bau.treemap_item(item_treemap, fullpath_file_treemap)\n",
    "        do_scatter = input(\"Scatter plot for the item (y/n)? \")\n",
    "        if do_scatter == 'y':\n",
    "            bau.plot_counts(item_treemap, fullpath_file_treemap)\n",
    "        do_histo = input(\"Histogram plot for the item (y/n)? \")\n",
    "        if do_histo == 'y':\n",
    "            bau.plot_histo(item_treemap, fullpath_distrib_item)\n",
    "        renew_treemap = input(\"\\n\\nTreemap for a new item (y/n)? \")\n",
    "\n",
    "# Initialize the variable G_coupl that will receive the biblioanalysis coupling graphs\n",
    "try: G_coupl\n",
    "except NameError: G_coupl = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp;II-2.1.1 Data parsing / Corpus description / Filtering the data and filtered corpus description\n",
    "To be run after corpus description to allow using the following functions : describe_corpus() , treemap_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries import\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil                      \n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "## Recursive filtering\n",
    "\n",
    "# Allows prints in filter_corpus_new function\n",
    "verbose = False\n",
    "\n",
    "# Initialization of parameters for recursive filtering\n",
    "filtering_step = 1\n",
    "while True:\n",
    "\n",
    "    ## Building the names of the useful folders and creating the output folder if not find \n",
    "    if filtering_step == 1:\n",
    "        in_dir_filter = out_dir_parsing\n",
    "        ### Get the folder for the filter configuration file         \n",
    "        gui_titles = {'main':   'Folder selection window for the config_filters.json file ',\n",
    "                      'result': 'Selected folder'}\n",
    "        gui_buttons = ['SELECTION','HELP']\n",
    "        filter_config_folder = bau.select_folder_gui_new(user_root, gui_titles, gui_buttons, bau.GUI_DISP)\n",
    "        \n",
    "        print('Filter configuration folder:', filter_config_folder)\n",
    "        file_config_filters = filter_config_folder / Path('config_filters.json')\n",
    "        print('Filter configuration file:',file_config_filters)\n",
    "        modif_filtering = input(\"Modification of item-values list from a predefined file (y/n)? \")\n",
    "        if modif_filtering == \"y\":\n",
    "            bau.filters_modification(filter_config_folder,file_config_filters)    \n",
    "    else:\n",
    "        renew_filtering = input(\"Apply a new filtering process (y/n)? \") \n",
    "        if renew_filtering == \"n\": break\n",
    "        in_dir_filter = project_folder / Path(bau.FOLDER_NAMES['filtering'] + '_' + str(filtering_step-1))\n",
    "        file_config_filters = in_dir_filter / Path('save_config_filters.json')\n",
    "        print('Filter configuration file:',file_config_filters) \n",
    "        \n",
    "    out_dir_filter = project_folder / Path(bau.FOLDER_NAMES['filtering'] + '_' + str(filtering_step))\n",
    "            \n",
    "    if not os.path.exists(out_dir_filter):\n",
    "        os.mkdir(out_dir_filter)\n",
    "    else:\n",
    "        print('out_dir_filter exists')\n",
    "        files = glob.glob(str(out_dir_filter) + '/*.*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "    # Building the absolute file name of filter configuration file to save for the filtering step\n",
    "    save_config_filters = out_dir_filter / Path(bau.SAVE_CONFIG_FILTERS)\n",
    "    print('\\nSaving filter configuration file:',save_config_filters)\n",
    "    \n",
    "    # Configurating the filtering through a dedicated GUI or getting it from the existing file\n",
    "    bau.filters_selection(file_config_filters,save_config_filters,in_dir_filter)\n",
    "    shutil.copyfile(save_config_filters, file_config_filters)\n",
    "\n",
    "    # Read the filtering status\n",
    "    combine,exclusion,filter_param = bau.read_config_filters(file_config_filters) \n",
    "    print(\"\\nFiltering status:\")\n",
    "    print(\"   Combine   :\",combine)\n",
    "    print(\"   Exclusion :\",exclusion)\n",
    "    for key,value in filter_param.items():\n",
    "        print(f\"   Item      : {key}\\n   Values    : {value}\\n\")\n",
    "\n",
    "    # Running function filter_corpus_new\n",
    "    bau.filter_corpus_new(in_dir_filter, out_dir_filter, verbose, file_config_filters) # <---???\n",
    "    file = out_dir_filter /Path('articles.dat')\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        articles_number = len(lines)\n",
    "    if articles_number == 0:\n",
    "        print('Filtered corpus empty !')\n",
    "        break\n",
    "    print(\"Filtered-corpus parsing saved in folder \", \n",
    "            str(out_dir_filter),\n",
    "            \" with the corresponding filters configuration\")\n",
    "\n",
    "        # Folder containing the wos or scopus parsed and filtered files\n",
    "    in_dir_freq_filt = out_dir_filter\n",
    "\n",
    "        # Folder containing the wos or scopus parsed, filtered and analysed files\n",
    "    out_dir_freq_filt = project_folder / Path(bau.FOLDER_NAMES['description'] + '_' + str(filtering_step))\n",
    "    if not os.path.exists(out_dir_freq_filt): os.mkdir(out_dir_freq_filt)\n",
    "\n",
    "        # Running describe_corpus \n",
    "    verbose = False\n",
    "    bau.describe_corpus(in_dir_freq_filt, out_dir_freq_filt, database_type, verbose)\n",
    "    print(\"Filtered corpus description saved in folder:\", str(out_dir_freq_filt))\n",
    "\n",
    "    # Treemap plot by a corpus item after filtering\n",
    "    make_treemap = 'n'\n",
    "    make_treemap = input(\"\\n\\nDraw treemap (y/n)?\")\n",
    "    if make_treemap == 'y' :\n",
    "\n",
    "            # Running plot of treemap for selected item_treemap\n",
    "        renew_treemap = 'y'    \n",
    "        while renew_treemap == 'y' :\n",
    "            print('\\n\\nChoose the item for treemap of the filtered corpus description in the tk window')\n",
    "            item_treemap = bau.item_selection()\n",
    "            file_name_treemap = project_folder / Path(bau.FOLDER_NAMES['description'] + '_'\\\n",
    "                                                      + str(filtering_step) + '/' + 'freq_'+ item_treemap +'.dat')\n",
    "            print(\"Item selected:\",item_treemap)\n",
    "            bau.treemap_item(item_treemap, file_name_treemap)\n",
    "            renew_treemap = input(\"\\n\\nTreemap for a new item (y/n)? \") \n",
    "\n",
    "    filtering_step += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp;II-2.1.2 Data parsing / Corpus Description / Bibliographic Coupling analysis\n",
    "To be run after corpus description to use the frequency analysis. You may execute the bibliographic coupling script several times successively on unfiltered corpus and on available filtering steps of the corpus.\n",
    "The result files are saved in independant folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries import\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "# Building the names of the useful folders and creating the output folder if not find  \n",
    "filtering = input(\n",
    "                  \"Corpus filtered (y/n)? \"\n",
    "                 )   \n",
    "if filtering == \"y\":\n",
    "    filtering_step = input(\n",
    "                            \"Enter filtering step : \"\n",
    "                          ) \n",
    "    in_dir_coupling = project_folder / Path(bau.FOLDER_NAMES['filtering'] + '_' + str(filtering_step))\n",
    "    in_dir_freq= project_folder / Path(bau.FOLDER_NAMES['description'] + '_' + str(filtering_step))\n",
    "    out_dir_coupling = project_folder / Path(bau.FOLDER_NAMES['coupling'] + '_' + str(filtering_step))\n",
    "else:\n",
    "    in_dir_coupling = out_dir_parsing\n",
    "    in_dir_freq= out_dir_corpus    \n",
    "    out_dir_coupling = project_folder / Path(bau.FOLDER_NAMES['coupling'])\n",
    "\n",
    "if not os.path.exists(out_dir_coupling):\n",
    "    os.mkdir(out_dir_coupling)\n",
    "else:\n",
    "    print('out_dir_coupling exists')\n",
    "    files = glob.glob(str(out_dir_coupling) + '/*.html')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    \n",
    "# Building the coupling graph of the corpus\n",
    "print('Building the coupling graph of the corpus, please wait...')\n",
    "G_coupl = bau.build_coupling_graph(in_dir_coupling)\n",
    "\n",
    "# Building the partition of the corpus\n",
    "print('Building the partition of the corpus, please wait...')\n",
    "G_coupl,partition = bau.build_louvain_partition(G_coupl)\n",
    "print()\n",
    "\n",
    "# Adding attributes to the coupling graph nodes\n",
    "attr_dic = {}\n",
    "add_attrib = input(\"Add attributes to the coupling graph nodes (y/n)? \")\n",
    "if add_attrib == 'y':\n",
    "    while True:\n",
    "        print('\\n\\nChoose the item for the attributes to add in the tk window')\n",
    "        item, m_max_attrs = bau.coupling_attr_selection()\n",
    "        attr_dic[item] = m_max_attrs\n",
    "        print(\"Item selected:\",item,\" with \",m_max_attrs, \" attributes\" )\n",
    "        G_coupl = bau.add_item_attribute(G_coupl, item, m_max_attrs, in_dir_freq, in_dir_coupling)\n",
    "        renew_attrib = input(\"\\nAdd attributes for a new item (y/n)?\") \n",
    "        if renew_attrib == 'n' : break      \n",
    "\n",
    "# Plot control of the coupling graph before using Gephy\n",
    "NODES_NUMBER_MAX = 1\n",
    "bau.plot_coupling_graph(G_coupl,partition,nodes_number_max=NODES_NUMBER_MAX)\n",
    "\n",
    "# Creating a Gephy file of the coupling graph  \n",
    "bau.save_graph_gexf(G_coupl,out_dir_coupling)\n",
    "print(\"\\nCoupling analysis of the corpus saved as Gephy file in folder:\\n\", str(out_dir_coupling))\n",
    "\n",
    "# Creating an EXCEL file of the coupling analysis results\n",
    "bau.save_communities_xls(partition,in_dir_coupling,out_dir_coupling)\n",
    "print(\"\\nCoupling analysis of the corpus saved as EXCEL file in folder:\\n\", str(out_dir_coupling))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp;&emsp;II-2.1.3  HTML graph of coupling analysis \n",
    "##### after Data parsing / Corpus Description / Coupling analysis  \n",
    "You may execute the HTML graph construction script several times successively on the available coupling graph of the corpus. The result files are saved in the corresponding coupling floder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating html file of graph G using pyviz\n",
    "   This script uses the results of the Biblioanalysis coupling analysis:\n",
    "   - out_dir_coupling (Path): path for saving the coupling analysis results;\n",
    "   - G (networkx object): coupling graph with added attributes;\n",
    "   - partition (dict):  partition of graph G;\n",
    "   - attr_dic (dict): dict of added attributes with number of added values. \n",
    "   \n",
    "'''\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "# Checking the availability of the corpus coupling graph G with all attributes and its partition\n",
    "assert(G_coupl is not None),'''Please run first the \"Bibliographic coupling analysis\" \n",
    "                                script to build the coupling graph'''\n",
    "\n",
    "# Setting the item label among the added attribute to be colored\n",
    "colored_attr = input('Please enter the item label among the added attributes to be colored (default: S)')\n",
    "if colored_attr == '':colored_attr = 'S'\n",
    "print('Attribute to be colored:',colored_attr)\n",
    "if colored_attr == 'S': \n",
    "    heading3 = 'Colored by main discipline (grey: without filtering subjects as main discipline).'\n",
    "else:\n",
    "    heading3 = 'Colored by main attribute values (grey: without filtering attribute values as main discipline).'\n",
    "assert(colored_attr in attr_dic.keys()),\\\n",
    "    f'''Selected colored attribute should be among the added attributes: {list(attr_dic.keys())}.\n",
    "Please run this script again to select an effectivelly added attribute to the coupling graph node \n",
    "or run again the \"Bibliographic coupling analysis\" script to add the targetted attribute to the coupling graph.'''\n",
    "\n",
    "# Setting the colors for the values of the attribute to be colored\n",
    "# default: values of 'S' item from a particular corpus\n",
    "# TO DO: define the list of the attribute values through a GUI\n",
    "colored_attr_values = {'Neurosciences & Neurology':'0',\n",
    "                  'Psychology':'1',\n",
    "                  'Computer Science':'2',\n",
    "                  'Robotics,Automation & Control Systems':'3',\n",
    "                  'Life Sciences & Biomedicine - Other Topics':'4',\n",
    "                  'Biochemistry & Molecular Biology':'4',\n",
    "                  'Cell Biology':'4',\n",
    "                  'Evolutionary Biology':'4',\n",
    "                  'Biomedical Social Sciences':'4',\n",
    "                  'Biotechnology & Applied Microbiology':'4',\n",
    "                  'Developmental Biology':'4',\n",
    "                  'Microbiology':'4',\n",
    "                  'Marine & Freshwater Biology':'4',\n",
    "                  'Reproductive Biology':'4',\n",
    "                  'Genetics & Heredity':'4',\n",
    "                  'Philosophy':'5',\n",
    "                  'History & Philosophy of Science':'5',\n",
    "                  'Social Sciences - Other Topics':'6',\n",
    "                  'Mathematical Methods In Social Sciences':'6',\n",
    "                  'Linguistics':'7',\n",
    "                  'Anthropology':'8',\n",
    "                 }\n",
    "\n",
    "# Setting the attribute value to be specifically shaped\n",
    "shaped_attr = input('Please enter the added attribute value to be specifically shaped (default: Psychology)')\n",
    "if shaped_attr == '':shaped_attr = 'Psychology'\n",
    "print('Attribute value to be specifically shaped (triangle):',shaped_attr)\n",
    "heading4 = 'Triangles for \"' + shaped_attr + '\" in disciplines.'\n",
    "\n",
    "# Computing the number of communities\n",
    "community_number = len(set(partition.values()))\n",
    "print('Number of communities:',community_number)\n",
    "\n",
    "# Computing the size of the communities\n",
    "communities_size = {}\n",
    "for value in set(partition.values()):\n",
    "    communities_size[value]=0\n",
    "    for key in set(partition.keys()):\n",
    "        if partition[key] == value:\n",
    "            communities_size[value]+=1\n",
    "            \n",
    "# Building the html graphs per community\n",
    "for community_id in range(community_number):\n",
    "    community_size = communities_size[community_id] \n",
    "    heading2 = 'Coupling graph for community ID: ' + str(community_id) + ' Size: ' + str(community_size)\n",
    "    heading = '<h1>' + main_heading + '</h1>' + '<h2>' + heading2 + '</h2>' \\\n",
    "                  + '<h3 align=left nowrap>' + heading3 + '<br>'  + heading4 + '</h3>'\n",
    "    html_file= str(out_dir_coupling /Path('coupling_' + 'com' + str(community_id) \\\n",
    "                                          + '_size' + str(community_size) + '.html'))\n",
    "    #bau.coupling_graph_html_plot(G_coupl,html_file,community_id,attr_dic,colored_attr,\n",
    "    #                             colored_attr_values,shaped_attr,nodes_colors,edges_color,\n",
    "    #                             background_color,font_color,heading)\n",
    "    bau.coupling_graph_html_nwplt(G_coupl,html_file,community_id,attr_dic,colored_attr,\n",
    "                                  colored_attr_values,shaped_attr,heading)\n",
    "# Building the html graph for the full corpus\n",
    "heading2  = ' All ' + str(community_number) + ' communities'\n",
    "heading = '<h1>' + main_heading + '</h1>' + '<h2>' + heading2 + '</h2>' \\\n",
    "          + '<h3 align=left nowrap>' + heading3 + '<br>'  + heading4 + '</h3>'\n",
    "html_file= str(out_dir_coupling /Path('coupling_' + 'all.html'))\n",
    "#bau.coupling_graph_html_plot(G_coupl,html_file,'all',attr_dic,colored_attr,\n",
    "#                         colored_attr_values,shaped_attr,nodes_colors,edges_color,\n",
    "#                         background_color,font_color,heading)\n",
    "bau.coupling_graph_html_nwplt(G_coupl,html_file,'all',attr_dic,colored_attr,\n",
    "                              colored_attr_values,shaped_attr,heading)\n",
    "\n",
    "print(\"\\nCreated html files of graph G_coupl using pyviz for the corpus in folder:\\n\", str(out_dir_coupling))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp;&emsp;II-2.2 Data parsing / Co-occurrence Maps\n",
    "You may execute the co-occurence script several times successively on unfiltered corpus and on available filtering steps of the corpus.\n",
    "The result files are saved in independant folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "# Building the names of the useful folders and creating the output folder if not find \n",
    "filtering = input(\n",
    "                  \"Corpus filtered (y/n)? \"\n",
    "                 )   \n",
    "if filtering == \"y\":\n",
    "    filtering_step = input(\n",
    "                            \"Enter filtering step : \"\n",
    "                          ) \n",
    "    in_dir_cooc = project_folder / Path(bau.FOLDER_NAMES['filtering'] + '_' + str(filtering_step))\n",
    "    out_dir_cooc = project_folder / Path(bau.FOLDER_NAMES['cooccurrence'] + '_' + str(filtering_step))\n",
    "else:\n",
    "    in_dir_cooc = out_dir_parsing   \n",
    "    out_dir_cooc = project_folder / Path(bau.FOLDER_NAMES['cooccurrence']) \n",
    "\n",
    "if not os.path.exists(out_dir_cooc):\n",
    "    os.mkdir(out_dir_cooc)\n",
    "else:\n",
    "    print('out_dir_cooc available')\n",
    "\n",
    "## Building the co-ocurrence graph\n",
    "size_min = 1\n",
    "node_size_ref=300\n",
    "while True :\n",
    "    print('\\n\\nChoose the item for co-occurrence analysis in the tk window')\n",
    "    cooc_item, size_min = bau.cooc_selection() \n",
    "    print(\"Item selected:\",cooc_item,\" at minimum size \",size_min)\n",
    "    out_dir_cooc_item = out_dir_cooc / Path('cooc_' + cooc_item + \\\n",
    "                                            '_thr' + str(size_min))\n",
    "    if not os.path.exists(out_dir_cooc_item):\n",
    "        os.mkdir(out_dir_cooc_item)\n",
    "    else:\n",
    "        print('out_dir_cooc_item available')\n",
    "    G_cooc = bau.build_item_cooc(cooc_item,in_dir_cooc, out_dir_cooc_item, size_min = size_min)\n",
    "    if G_cooc is None:\n",
    "        print(f'The minimum node size ({size_min}) is two large. Relax this constraint.')\n",
    "    else:\n",
    "        print(\"Co-occurrence analysis of the corpus for item \" + cooc_item + \\\n",
    "          \" saved in folder:\", str(out_dir_cooc_item))\n",
    "        heading2 = 'Co_occurence graph for item ' + cooc_item + ' with minimum node size ' + str(size_min)\n",
    "        heading3 = 'Bold node title: Node attributes[number of item value occurrences-item value (total number of edges)]'\n",
    "        heading4 = 'Light node titles: Neighbors attributes[number of item value occurrences-item value (number of edges with node)]'\n",
    "        heading = '<h1>' + main_heading + '</h1>' + '<h2>' + heading2 + '</h2>' \\\n",
    "                  + '<h3 align=left nowrap>' + heading3 + '<br>'  + heading4 + '</h3>'\n",
    "    \n",
    "        bau.plot_cooc_graph(G_cooc,cooc_item,size_min=size_min,node_size_ref=node_size_ref)\n",
    "        # Creating html file of graph G_cooc using pyviz\n",
    "        html_file= str(out_dir_cooc_item /Path('cooc_' + cooc_item + '_thr' + str(size_min) + '.html'))\n",
    "        bau.cooc_graph_html_plot(G_cooc,html_file,heading)\n",
    "        print(\"Created html file of\",cooc_item,\"co-occurrence graph using pyviz in folder:\\n\",\\\n",
    "              str(out_dir_cooc_item))\n",
    "        \n",
    "    renew_cooc = input(\"\\n\\nCo-occurrence analysis for a new item (y/n)?\") \n",
    "    if renew_cooc == 'n' : break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III- Temporal development of item values weight\n",
    "To run this cell a set of annual corpuses with their description should be available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries import\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "# Initialize the search configuration dict \n",
    "keyword_filters = {\n",
    "    'is_in':[],    \n",
    "    'is_equal':[]}\n",
    "\n",
    "## Get the folder for the configuration file for the temporal development analysis \n",
    "temporaldev_config_folder = bau.select_folder_gui(user_root,'Select the folder for config_temporal.json file')\n",
    "print('Item_values selection folder:', temporaldev_config_folder )\n",
    "\n",
    "## Building the search configuration:\n",
    "#### - either by reading of the 'config_temporal.json' without modification\n",
    "#### - or by an interactive modification of the configuration and storing it in this file for a futher use\n",
    "TemporalDev_file = temporaldev_config_folder / Path('config_temporal.json')\n",
    "\n",
    "keywords_modif = input('Modification of the keywords list (y/n)?')\n",
    "if keywords_modif == 'y':\n",
    "    \n",
    "        # Selection of items\n",
    "    items_full_list = ['IK','AK','TK','S','S2']\n",
    "    print('\\nPlease select the items to be analyzed via the tk window')\n",
    "    items = bau.Select_multi_items(items_full_list,'multiple')\n",
    "\n",
    "        # Selection of the folder of item-values full-list file\n",
    "    select_folder = bau.select_folder_gui(user_root,'Select the folder of the item-values list files')\n",
    "\n",
    "        # Setting the file of the item-values full list  \n",
    "    keywords_full_list_file = select_folder / Path('TempDevK_full.txt')\n",
    "    \n",
    "        # Setting the list of item-values full list\n",
    "    keywords_full_list = bau.item_values_list(keywords_full_list_file)\n",
    "    \n",
    "        # Selection of the item-values list to be put in the temporal development configuration file \n",
    "    search_modes = ['is_in','is_equal']\n",
    "    for search_mode in search_modes:\n",
    "        print('\\nPlease select the keywords for ',search_mode, ' via the tk window')\n",
    "        keyword_filters[search_mode] = bau.Select_multi_items(keywords_full_list,mode = 'multiple')\n",
    "        \n",
    "    # Saving the new configuration in the 'config_temporal.json' file   \n",
    "    bau.write_config_temporaldev(TemporalDev_file,items,keyword_filters)\n",
    "    print('\\n New temporal development configuration saved in: \\n', TemporalDev_file)    \n",
    "else:\n",
    "    # Reading the search configuration from the 'config_temporal.json' file  \n",
    "    items,keywords_param = bau.read_config_temporaldev(TemporalDev_file)\n",
    "    print('Selection of items:\\n',items)    \n",
    "    keyword_filters['is_in'] = keywords_param['is_in']\n",
    "    keyword_filters['is_equal'] = keywords_param['is_equal']\n",
    "\n",
    "## Selection of annual corpus files\n",
    "corpusfiles_list = os.listdir(corpuses_folder)\n",
    "corpusfiles_list.sort()\n",
    "print('\\nPlease select the corpuses to be analyzed via the tk window')\n",
    "years = bau.Select_multi_items(corpusfiles_list,'multiple')\n",
    "\n",
    "# Print configuration\n",
    "print('Search items:', items)\n",
    "print('\\nSearch Words:\\n' + json.dumps(keyword_filters, indent=2))\n",
    "print('\\n Selection of annual corpus files:\\n',years, '\\n')\n",
    "\n",
    "# Performing the search using the keyword_filters dict\n",
    "keyword_filter_list = bau.temporaldev_itemvalues_freq(keyword_filters ,items, years, corpuses_folder)\n",
    "\n",
    "# Saving the search results in an EXCEL file\n",
    "store_file = corpuses_folder / Path('Results_Files/TempDev_synthesis.xlsx')\n",
    "bau.temporaldev_result_toxlsx(keyword_filter_list,store_file)\n",
    "print('\\nTemporal development results saved in:\\n', store_file) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexe 1- Databases merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "database, filename, in_dir, out_dir = bau.merge_database_gui()\n",
    "bau.merge_database(database,filename,in_dir,out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexe 2- Item values selection to list for filters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "# Get the folder for the filter configuration file \n",
    "filter_config_folder = bau.select_folder_gui(user_root,'Select the folder for the config_filters.json file')\n",
    "print('Filter configuration folder:', filter_config_folder) \n",
    "\n",
    "file_config_filters = filter_config_folder/ Path('config_filters.json')    \n",
    "bau.filters_modification(filter_config_folder,file_config_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parsing\n",
    "- articles.dat is the central file, listing all the publications within the corpus. It contains informations such as the document type (article, letter, review, conf proceeding, etc), title, year of publication, publication source, doi, number of citations (given by WOS or Scopus at the time of the extraction) AND a unique identifier used in all the other files to identify a precise publication.\n",
    "- database.dat keeps track of the origin of the data, some part of the analysis being specific to WOS or Scopus data.\n",
    "- authors.dat lists all authors names associated to all publications ID.\n",
    "- addresses.dat lists all adresses associated to all publications ID, along with a specific ID for each adresse line. These adresses are reported as they appear in the raw data, without any further processing.\n",
    "- countries.dat lists all countries associated to all publications ID and adresses lines ID. The countries are extracted from the adresses fields of the raw data, with some cleaning (changing mentions of US states and UK countries to respectively the USA and UK).\n",
    "- institutions.dat lists all the comma-separated entities appearing in the adresses field associated to all publications ID and adresses lines ID, except those refering to a physical adresses. These entities correspond to various name variants of universities, organisms, hospitals, labs, services, departments, etc as they appear in the raw data. No treatment is made to e.g. filtering out the entities corresponding a given hierarchy level.\n",
    "- keywords.dat lists various types of keywords associated to all publications ID. \"AK\" keywords correspond to Author's keywords. \"IK\" keywords correspond to either WOS or Scopus keywords, which are built based on the authors' keywords, the title and abstract. \"TK\" correspond to title words (from which we simply remove common words and stop words - no stemming is performed). TK are especially useful when studying pre-90's publications, when the use of keywords was not yet standard.\n",
    "- references.dat lists all the references associated to all publications ID. The rawdata is parsed to store the first author name, title, source, volume and page of each reference of the raw \"references\" field.\n",
    "- subjects.dat lists all subject categories associated to all publications ID (a journal may be associated to many subject category). WOS classifies the sources it indexes into ∼ 250 categories, that are reported in the extracted data. Scopus classifies its sources into 27 major categories and ∼ 300 sub-categories, none of which are reported in the extracted data. We use Elsevier Source Title List (october 2017 version) to retrieve that information. The \"subject.dat\" contains the info relative to the major categories.\n",
    "- subjects2.dat lists Scopus's sub-categories, if the use database is Scopus.\n",
    "- AA_log.txt keeps track of the date/time the script was executed and of all the messages displayed on the terminal (number of publications extracted, % of references rejected, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Corpus description\n",
    "Before doing anything else, you should get a general idea of the content of your database.  This script performs several basic tasks:\n",
    "- it performs a series of frequency analysis, computing the number of occurrences of each item (authors, keywords, references, etc) within the publications of the corpus. These frequencies are automatically stored into several \"freq_xxx.dat\" files within a newly created \"freq\" folder.\n",
    "- it performs a series of generic statistical analysis, storing the numbers of distinct items of each type (e.g. there are x distinct keyword in the corpus ), the distributions of number of occurrences of each item (e.g. there are x keywords appearing in at least y publications) and the distribution of number of items per publication (e.g.there are x% of publications with y keywords). All these statistics are stored in the \"DISTRIBS_itemuse.json\" file.\n",
    "- it also performs a co-occurrence analysis, computing the number of co-occurrence of pairs of items among the top 100 most frequent items of each type (e.g. computing how often the two most used keywords appear together in the same publications). The results of this analysis are stored in the \"coocnetworks.json\" file. More systematic co-occurrence analysis can also be performed with another script, cf the Co-occurrence Maps section below.\n",
    "All the generated files can be opened and read with a simple text editor. The freq_xxx.dat, listing items by order of frequency, can also be read in a spreadsheet software such as excel. All the files are however primarily made to be read in the BiblioMaps interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data\n",
    "#### To be run after corpus description to allow using the following functions : describe_corpus() , treemap_item()\n",
    "\n",
    "If, upon exploring the nature of the data you realize that before going further you'd prefer to filter your corpus based on some characteristic (keeping only the publications from certain years, using some keywords or references, written by some authors from some countries, etc), you can filter the initial corpus thanks to the script:\n",
    "\n",
    "- python BiblioTools3.2/filter.py -i myprojectname/ -o myprojectname_filtered -v <br>\n",
    "\n",
    "Edit the 'filter.py' file to specify your filters. You'll also need to create a new \"myprojectname_filtered\" main folder before running the script.\n",
    "- create the files articles.dat, addresses.dat, authors.dat, countries.dat, institutions.dat, keywords.dat, references.dat, subjects.dat, subjects2.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurrence Maps\n",
    "You may execute the co-occurrence script several times successively on unfiltered corpus and on available filtering steps of the corpus.\n",
    "The result files are saved in independant folders.\n",
    "\n",
    "The script create multiple co-occurrence networks, all stored in gdf and gexf files that can be opened in Gephi, among which:\n",
    "\n",
    "Example of heterogeneous network generated with BiblioAnlysis and visualized in Gephi.\n",
    "\n",
    "- a co-cocitation network, linking references that are cited in the same publications.\n",
    "- a co-refsources network, linking references's sources that are cited in the same publications.\n",
    "- a co-author network, linking authors that collaborated in some publications.\n",
    "- a co-country network, linking countries with researchers that collaborated in some publications.\n",
    "- a co-institution network, linking institutions with researchers that collaborated in some publications. For this network to be fully useful, you may want to spend some time cleaning the \"institutions.dat\", e.g. by keeping only the big institutions (university level) or by replacing minor name variant by the dominant name variant (\"Ecole Normale Supérieure de Lyon\" → \"ENS Lyon\")\n",
    "- a co-keyword network, linking keywords being co-used in some publications. Be careful about the interpretation: keywords can be polysemic, their meaning differing from field to another (eg \"model\", \"energy\", \"evolution\", etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of GUI\n",
    "on going work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from BiblioGui.py not modified\n",
    "\n",
    "def _str_size_mm(text, font, ppi):\n",
    "    '''The function `_str_size_mm` computes the sizes in mm of a string.\n",
    "\n",
    "    Args:\n",
    "        text (str): the text of which we compute the size in mm.\n",
    "        font (tk.font): the font of the text.\n",
    "        ppi (int): pixels per inch of the display.\n",
    "\n",
    "    Returns:\n",
    "        `(tuple)`: width in mm `(string)`, height in mm `(string)`.\n",
    "\n",
    "    Note:\n",
    "        The use of this function requires a tkinter window availability \n",
    "        since it is based on a tkinter font definition.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Local imports\n",
    "    #from .BiblioGeneralGlobals import IN_TO_MM\n",
    "    \n",
    "    IN_TO_MM = bau.IN_TO_MM\n",
    "       \n",
    "    (w_px,h_px) = (font.measure(text),font.metrics(\"linespace\"))\n",
    "    w_mm = w_px * IN_TO_MM / ppi\n",
    "    h_mm = h_px * IN_TO_MM / ppi\n",
    "\n",
    "    return (w_mm,h_mm )\n",
    "\n",
    "\n",
    "def _str_max_len_mm(list_strs,font,ppi): \n",
    "    '''The `_str_max_len_mm`function gets the maximum length in mm of a list of strings \n",
    "       given the font and the ppi of the used display and using the `_str_size_mm` function .\n",
    "       \n",
    "    Args:\n",
    "        list_strs (list): list of strings to be sized to get their maximum length.\n",
    "        font (tk.font): the font used for the strings size evaluation in mm.\n",
    "        ppi (int): pixels per inch of the display.\n",
    "        \n",
    "    Returns:\n",
    "        `(float)`: maximum length in mm of the strings in `list_strs`.\n",
    "    '''                   \n",
    "    \n",
    "    max_length_mm = max([_str_size_mm(value, font, ppi)[0] \n",
    "                         for value in list_strs])\n",
    "    return max_length_mm\n",
    "\n",
    "\n",
    "def _mm_to_px(size_mm,ppi, fact=1):\n",
    "    '''The `_mm_to_px' function converts a value in mm to a value in pixels\n",
    "    using the ppi of the used display and a factor fact.\n",
    "    \n",
    "    Args:\n",
    "        size_mm (float): value in mm to be converted.\n",
    "        ppi ( float): pixels per inch of the display.\n",
    "        fact (float): factor (default= 1).\n",
    "        \n",
    "    Returns:\n",
    "        `(int)`: upper integer value of the conversion to pixels\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Standard library imports \n",
    "    import math\n",
    "    \n",
    "    # Local imports\n",
    "    #from .BiblioGeneralGlobals import IN_TO_MM\n",
    "    \n",
    "    IN_TO_MM = bau.IN_TO_MM\n",
    "\n",
    "    size_px = math.ceil((size_mm * fact / IN_TO_MM) * ppi)\n",
    "    \n",
    "    return size_px\n",
    "\n",
    "\n",
    "def _split_path2str(in_str,sep,max_px,font,ppi):\n",
    "    '''The `_split_path2str` function splits the `in_str` string \n",
    "    in substrings of pixels sizes lower than `max_px` using the separator `sep` .\n",
    "\n",
    "    Args:\n",
    "        in_str (str): the full path of a folder.\n",
    "        sep (str): the character to be find in `in_str`.\n",
    "        max_px (int): the maximum size in pixels for the substrings \n",
    "                      that should result from the split of `in-dir`.\n",
    "        font (tk.font): the font used for the substrings size evaluation in mm.\n",
    "        ppi (float): pixels per inch of the display.\n",
    "\n",
    "    Returns:\n",
    "        `(tuple)`: tuple of the substrings resulting from the split of `in-dir`.\n",
    "\n",
    "    Note:\n",
    "        The use of this function requires a tkinter window availability \n",
    "        since it is based on a tkinter font definition.\n",
    "\n",
    "    '''        \n",
    "\n",
    "    # Standard library imports \n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    len_in_str,_ = _str_size_mm(in_str, font, ppi)\n",
    "    if _mm_to_px(len_in_str,ppi)>int(max_px):\n",
    "        pos_list = np.array([m.start() for m in re.finditer(r'[\\\\' + sep + ']', in_str)])\n",
    "        list_len = [_mm_to_px(_str_size_mm(in_str[0:pos_slash], font, ppi)[0],ppi)\n",
    "                    for pos_slash in pos_list ]\n",
    "        try:\n",
    "            pos_mid = pos_list[np.min(np.where(np.array(list_len) >= int(max_px))) - 1]\n",
    "        except:\n",
    "            pos_mid = pos_list[-1]\n",
    "        out_str1 = str(in_str)[0:pos_mid]\n",
    "        out_str2 = str(in_str)[pos_mid:]\n",
    "\n",
    "    else:\n",
    "        out_str1 = str(in_str)\n",
    "        out_str2 = ''\n",
    "\n",
    "    return (out_str1,out_str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_multi_files_gui(list_files, in_dir, titles, \n",
    "                           prime_disp=0, widget_ratio=1.2, max_lines_nb=3)):\n",
    "    \n",
    "    '''The function `select_multi_files_gui` allows the interactive selection of a file in the folder `in_dir`.\n",
    "    \n",
    "    Args: \n",
    "        in_dir (str): name of the initial folder.\n",
    "        titles (dict): title of the tk window.\n",
    "        prime_disp (int): number identifying the used display (default: 0).\n",
    "        widget_ratio (float): base ratio for defining the different widget ratii (default: 1.2).\n",
    "        max_lines_nb (int): maximum lines number for editing the selected folder name (default: 3).\n",
    "    \n",
    "    Returns:\n",
    "        `(str)`: selected file name.\n",
    "        \n",
    "    Note:\n",
    "        Uses the globals: `IN_TO_MM`;`DISPLAYS`.\n",
    "        Based on two frames in the main window and two buttons in the top frame.\n",
    "\n",
    "    '''\n",
    "    # Standard library imports \n",
    "    import math\n",
    "    import re\n",
    "    import tkinter as tk\n",
    "    from tkinter import messagebox\n",
    "    from tkinter import filedialog\n",
    "    import tkinter.font as TkFont\n",
    "    \n",
    "    # Local imports\n",
    "    #from .BiblioGeneralGlobals import IN_TO_MM\n",
    "    #from .BiblioSys import DISPLAYS\n",
    "    \n",
    "    IN_TO_MM = bau.IN_TO_MM\n",
    "    DISPLAYS = bau.DISPLAYS\n",
    "    \n",
    "    global out_file\n",
    "    \n",
    "    #############################################################################\n",
    "    yscrollbar = tk.Scrollbar(win)\n",
    "    yscrollbar.pack(side = tk.RIGHT, fill = tk.Y)\n",
    "    selectmode = tk.MULTIPLE\n",
    "    if mode == 'single':selectmode = tk.SINGLE\n",
    "    listbox = tk.Listbox(win, width=40, height=10, selectmode=selectmode,\n",
    "                     yscrollcommand = yscrollbar.set)\n",
    "\n",
    "    x = list_item\n",
    "    for idx,item in enumerate(x):\n",
    "        listbox.insert(idx, item)\n",
    "        listbox.itemconfig(idx,\n",
    "                           bg = \"white\" if idx % 2 == 0 else \"white\")\n",
    "    \n",
    "    def selected_item():\n",
    "        global val\n",
    "        val = [listbox.get(i) for i in listbox.curselection()]\n",
    "        if os.name == 'nt':\n",
    "            win.destroy()\n",
    "\n",
    "    btn = tk.Button(win, text='OK', command=selected_item)\n",
    "    btn.pack(side='bottom')\n",
    "\n",
    "    listbox.pack(padx = 10, pady = 10,expand = tk.YES, fill = \"both\")\n",
    "    yscrollbar.config(command = listbox.yview)\n",
    "\n",
    "    #############################################################################    \n",
    "    \n",
    " \n",
    "    ############# Definition of local functions #############    \n",
    "\n",
    "    def outdir_folder_choice():\n",
    "        '''The function `outdir_folder_choice' allows the interactive choice of a folder, \n",
    "        puts it in the `out_dir` global variable and prints the result in the `folder_choice` frame.\n",
    "\n",
    "        '''\n",
    "        # Standard library imports\n",
    "        import numpy as np\n",
    "\n",
    "        global out_dir\n",
    "\n",
    "        out_dir = filedialog.askdirectory(initialdir=in_dir,title=titles['main'])\n",
    "        \n",
    "        out_dir_split = [out_dir]\n",
    "        while out_dir_split[len(out_dir_split)-1]!='':\n",
    "            out_dir1,out_dir2 = _split_path2str(out_dir_split[len(out_dir_split)-1], \n",
    "                                                '/', frame_widthpx, text_font, ppi)\n",
    "            out_dir_split[len(out_dir_split)-1] = out_dir1\n",
    "            out_dir_split.append(out_dir2)\n",
    "\n",
    "         # Create the folder-result frame and set its geometry \n",
    "        folder_result = tk.LabelFrame(master=win,              \n",
    "                        text=titles['result'],\n",
    "                        font=frame_font)\n",
    "        folder_result.place(x=frame_xpx,\n",
    "                            y=frame_ypx,\n",
    "                            width=frame_widthpx,\n",
    "                            height=frame_heightpx)\n",
    "\n",
    "         # Edit the selected folder        \n",
    "        text_max_widthmm = _str_max_len_mm(out_dir_split, text_font, ppi)\n",
    "        text_xmm = (frame_widthmm - text_max_widthmm) / 2\n",
    "        text_xpx = _mm_to_px(text_xmm - mm_size_corr,ppi)\n",
    "        text_ypx = _mm_to_px(frame_unit_heightmm,ppi)       \n",
    "        text = '\\n'.join(out_dir_split)\n",
    "        folder_label = tk.Label(folder_result, text=text, font=text_font)\n",
    "        folder_label.place(x=text_xpx,\n",
    "                           y=text_ypx)\n",
    "    \n",
    "    def help():\n",
    "        messagebox.showinfo('Folder selection info', '')\n",
    "    \n",
    "    ############# Local parameters setting #############  \n",
    "    \n",
    "     # Get the ppi of the selected prime display\n",
    "    ppi = DISPLAYS[prime_disp]['ppi']\n",
    "    \n",
    "     # Check the number of frames and buttons\n",
    "    frames_nb = len(titles) -1 \n",
    "    buttons_nb = len(buttons_labels)\n",
    "    if frames_nb!=1 or buttons_nb!=2:\n",
    "        print('Number of titles:', len(titles) )\n",
    "        print('Number of buttons:', len(button_labels) )\n",
    "        print('The number of titles should be 2 and the number of buttons should be 2')\n",
    "    \n",
    "     # Set the ratio of frames-width to the titles-max-width\n",
    "    frame_ratio = widget_ratio\n",
    "    \n",
    "     # Set the ration of window-width to the frame-width\n",
    "    win_ratio = widget_ratio \n",
    "    \n",
    "     # Set the buttons-height to the label-height ratio to vertically center the label in the button\n",
    "    button_ratio = 2.5\n",
    "    \n",
    "     # Set a potential ratio for correcting the conversion of mm to px for the buttons sizes\n",
    "     # Todo: adapt these ratios to correct the discrepancy between the set mm sizes \n",
    "     # and the effective mm sizes on the screen for MacOs \n",
    "     # (correction still to be understood)\n",
    "    buttonsize_mmtopx_ratios = (1,1,1)\n",
    "    \n",
    "     # Set the value in mm for the correction of the sizes in milimeters \n",
    "     # before use for computing the widgets horizontal positions in pixels \n",
    "     # (correction still to be understood)\n",
    "    mm_size_corr = 1\n",
    "    \n",
    "     # Set the maximum lines number for editing the selected folder name\n",
    "    max_lines_nb = 3 \n",
    "    \n",
    "    ############# Tkinter window management #############\n",
    "    \n",
    "     # Create the tk window\n",
    "    win = tk.Tk()\n",
    "    win.attributes(\"-topmost\", True)\n",
    "    win.title(titles['main']) \n",
    "    \n",
    "     # Set the fonts to be used\n",
    "    frame_font = TkFont.Font(family='arial', size=16, weight='bold')\n",
    "    text_font = TkFont.Font(family='arial', size=12, weight='normal')\n",
    "    button_font = TkFont.Font(family='arial', size=12, weight='normal')\n",
    "    \n",
    "     # Computes the maximum size in mm of the list of titles\n",
    "    titles_mm_max = _str_max_len_mm(titles.values(), frame_font, ppi)\n",
    "    \n",
    "     # Computes button sizes in mm and pixels using button label sizes and button_ratio\n",
    "     # Buttons width is the button heigth added to the labels width to horizontally center the label in the button \n",
    "    labels_widthmm = [_str_size_mm(buttons_labels[i],button_font, ppi)[0] for i in range(buttons_nb)]\n",
    "    label_heightmm = _str_size_mm(buttons_labels[0],button_font, ppi)[1]\n",
    "    button_heightmm =  label_heightmm * button_ratio\n",
    "    buttons_widthmm = (labels_widthmm[0] + button_heightmm, labels_widthmm[1] + button_heightmm)\n",
    "    buttons_widthpx = (_mm_to_px(buttons_widthmm[0],ppi,buttonsize_mmtopx_ratios[0]), \n",
    "                       _mm_to_px(buttons_widthmm[1],ppi,buttonsize_mmtopx_ratios[1]))\n",
    "    button_heigthpx = _mm_to_px(button_heightmm,ppi,buttonsize_mmtopx_ratios[2])\n",
    "\n",
    "     # Computes the frame width in pixels from titles maximum size in mm using frame_ratio\n",
    "    frame_widthmm = titles_mm_max * frame_ratio    \n",
    "    frame_widthpx = str(_mm_to_px(frame_widthmm,ppi))\n",
    "\n",
    "     # Computes the window width in pixels from the frame width and buttons width using win_ratio\n",
    "    win_widthmm = max(frame_widthmm,sum(buttons_widthmm)) * win_ratio \n",
    "    win_widthpx = str(_mm_to_px(win_widthmm,ppi))\n",
    "\n",
    "     # Computes the buttons horizontal positions in pixels \n",
    "     # assuming 2 buttons and with correction of size in mm by mm_size_corr value\n",
    "    padx_ratio = buttons_nb * 2  \n",
    "    pad_xmm = (win_widthmm - min(frame_widthmm,sum(buttons_widthmm))) / padx_ratio\n",
    "    buttons_xmm = (pad_xmm, buttons_widthmm[0] + 3 * pad_xmm)\n",
    "    buttons_xpx = (_mm_to_px(buttons_xmm[0] - mm_size_corr,ppi), _mm_to_px(buttons_xmm[1] - mm_size_corr,ppi))\n",
    "\n",
    "     # Computes the frames heigth unit\n",
    "    _, text_heigthmm = _str_size_mm('Users/',text_font, ppi)\n",
    "    frame_unit_heightmm = min(button_heightmm,text_heigthmm) \n",
    "    print('frame_unit_heightmm:',frame_unit_heightmm)\n",
    "\n",
    "     # Computes the buttons vertical position in pixels\n",
    "    button_ymm = frame_unit_heightmm \n",
    "    print('buttons y pos:',button_ymm)\n",
    "    button_ypx = _mm_to_px(button_ymm,ppi)\n",
    "\n",
    "     # Computes the frame heigth in mm and in pixels \n",
    "    pads_nb = 4  # 2 frame units above and 2 frame units under the edited text \n",
    "    max_frame_unit_nb = pads_nb + max_lines_nb  \n",
    "    frame_heightmm = frame_unit_heightmm * max_frame_unit_nb\n",
    "    print('frame_heightmm:', frame_heightmm)\n",
    "    frame_heightpx = str(_mm_to_px(frame_heightmm,ppi))\n",
    "\n",
    "     # Computes the frame positions in pixels\n",
    "    frame_xmm = (win_widthmm - frame_widthmm) / 2\n",
    "    frame_ymm = button_ymm + button_heightmm + 2 * frame_unit_heightmm\n",
    "    print('frames x pos:',frame_xmm)\n",
    "    print('frames y pos:',frame_ymm)\n",
    "    frame_xpx, frame_ypx = _mm_to_px(frame_xmm,ppi), _mm_to_px(frame_ymm,ppi)\n",
    "\n",
    "    # Computes the window heigth in mm and in pixels \n",
    "    # with frame_unit_heightmm separating vertically the widgets\n",
    "    win_heightmm = button_ymm + button_heightmm + frame_heightmm + 3 * frame_unit_heightmm\n",
    "    print('win_heightmm:',win_heightmm)\n",
    "    win_heightpx = str(_mm_to_px(win_heightmm,ppi))\n",
    "\n",
    "     # Set the window geometry\n",
    "    win_xpx = str(int(DISPLAYS[prime_disp]['x']) + 50)\n",
    "    win_ypx = str(int(DISPLAYS[prime_disp]['y']) + 50)\n",
    "    win.geometry(f'{win_widthpx}x{win_heightpx}+{win_xpx}+{win_ypx}')\n",
    "    #win.resizable(0, 0)\n",
    "\n",
    "     # Create the folder result frame and set its geometry \n",
    "    folder_result = tk.LabelFrame(master=win,              \n",
    "                text=titles['result'],\n",
    "                font=frame_font)\n",
    "    folder_result.place(x=frame_xpx,\n",
    "                    y=frame_ypx,\n",
    "                    width=frame_widthpx,\n",
    "                    height=frame_heightpx)\n",
    "\n",
    "     # Create the button for folder selection\n",
    "    select_button = tk.Button(win,\n",
    "                          text=buttons_labels[0],\n",
    "                          font=button_font,\n",
    "                          command=outdir_folder_choice)\n",
    "    select_button.place(x=buttons_xpx[0], \n",
    "                    y=button_ypx, \n",
    "                    width=buttons_widthpx[0], \n",
    "                    height=button_heigthpx)\n",
    "\n",
    "     # Create the help button\n",
    "    help_button = tk.Button(win,\n",
    "                        text=buttons_labels[1],\n",
    "                        font=button_font,\n",
    "                        command=help)\n",
    "    help_button.place(x=buttons_xpx[1], \n",
    "                  y=button_ypx, \n",
    "                  width=buttons_widthpx[1], \n",
    "                  height=button_heigthpx)\n",
    "\n",
    "    win.mainloop()\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_multi_files_gui(list_files, in_dir, titles, \n",
    "                           prime_disp=0, widget_ratio=1.2, max_lines_nb=3)):\n",
    "    \n",
    "    '''The function `select_multi_files_gui` allows the interactive selection of a file in the folder `in_dir`.\n",
    "    \n",
    "    Args: \n",
    "        in_dir (str): name of the initial folder.\n",
    "        titles (dict): title of the tk window.\n",
    "        prime_disp (int): number identifying the used display (default: 0).\n",
    "        widget_ratio (float): base ratio for defining the different widget ratii (default: 1.2).\n",
    "        max_lines_nb (int): maximum lines number for editing the selected folder name (default: 3).\n",
    "    \n",
    "    Returns:\n",
    "        `(str)`: selected file name.\n",
    "        \n",
    "    Note:\n",
    "        Uses the globals: `IN_TO_MM`;`DISPLAYS`.\n",
    "        Based on two frames in the main window and two buttons in the top frame.\n",
    "\n",
    "    '''\n",
    "    # Standard library imports \n",
    "    import math\n",
    "    import re\n",
    "    import tkinter as tk\n",
    "    from tkinter import messagebox\n",
    "    from tkinter import filedialog\n",
    "    import tkinter.font as TkFont\n",
    "    \n",
    "    # Local imports\n",
    "    #from .BiblioGeneralGlobals import IN_TO_MM\n",
    "    #from .BiblioSys import DISPLAYS\n",
    "    \n",
    "    IN_TO_MM = bau.IN_TO_MM\n",
    "    DISPLAYS = bau.DISPLAYS\n",
    "    \n",
    "    global out_file\n",
    "    \n",
    "    #############################################################################\n",
    "    yscrollbar = tk.Scrollbar(win)\n",
    "    yscrollbar.pack(side = tk.RIGHT, fill = tk.Y)\n",
    "    selectmode = tk.MULTIPLE\n",
    "    if mode == 'single':selectmode = tk.SINGLE\n",
    "    listbox = tk.Listbox(win, width=40, height=10, selectmode=selectmode,\n",
    "                     yscrollcommand = yscrollbar.set)\n",
    "\n",
    "    x = list_item\n",
    "    for idx,item in enumerate(x):\n",
    "        listbox.insert(idx, item)\n",
    "        listbox.itemconfig(idx,\n",
    "                           bg = \"white\" if idx % 2 == 0 else \"white\")\n",
    "    \n",
    "    def selected_item():\n",
    "        global val\n",
    "        val = [listbox.get(i) for i in listbox.curselection()]\n",
    "        if os.name == 'nt':\n",
    "            win.destroy()\n",
    "\n",
    "    btn = tk.Button(win, text='OK', command=selected_item)\n",
    "    btn.pack(side='bottom')\n",
    "\n",
    "    listbox.pack(padx = 10, pady = 10,expand = tk.YES, fill = \"both\")\n",
    "    yscrollbar.config(command = listbox.yview)\n",
    "\n",
    "    #############################################################################    \n",
    "    \n",
    " \n",
    "    ############# Definition of local functions #############    \n",
    "\n",
    "    def outdir_folder_choice():\n",
    "        '''The function `outdir_folder_choice' allows the interactive choice of a folder, \n",
    "        puts it in the `out_dir` global variable and prints the result in the `folder_choice` frame.\n",
    "\n",
    "        '''\n",
    "        # Standard library imports\n",
    "        import numpy as np\n",
    "\n",
    "        global out_dir\n",
    "\n",
    "        out_dir = filedialog.askdirectory(initialdir=in_dir,title=titles['main'])\n",
    "        \n",
    "        out_dir_split = [out_dir]\n",
    "        while out_dir_split[len(out_dir_split)-1]!='':\n",
    "            out_dir1,out_dir2 = _split_path2str(out_dir_split[len(out_dir_split)-1], \n",
    "                                                '/', frame_widthpx, text_font, ppi)\n",
    "            out_dir_split[len(out_dir_split)-1] = out_dir1\n",
    "            out_dir_split.append(out_dir2)\n",
    "\n",
    "         # Create the folder-result frame and set its geometry \n",
    "        folder_result = tk.LabelFrame(master=win,              \n",
    "                        text=titles['result'],\n",
    "                        font=frame_font)\n",
    "        folder_result.place(x=frame_xpx,\n",
    "                            y=frame_ypx,\n",
    "                            width=frame_widthpx,\n",
    "                            height=frame_heightpx)\n",
    "\n",
    "         # Edit the selected folder        \n",
    "        text_max_widthmm = _str_max_len_mm(out_dir_split, text_font, ppi)\n",
    "        text_xmm = (frame_widthmm - text_max_widthmm) / 2\n",
    "        text_xpx = _mm_to_px(text_xmm - mm_size_corr,ppi)\n",
    "        text_ypx = _mm_to_px(frame_unit_heightmm,ppi)       \n",
    "        text = '\\n'.join(out_dir_split)\n",
    "        folder_label = tk.Label(folder_result, text=text, font=text_font)\n",
    "        folder_label.place(x=text_xpx,\n",
    "                           y=text_ypx)\n",
    "    \n",
    "    def help():\n",
    "        messagebox.showinfo('Folder selection info', '')\n",
    "    \n",
    "    ############# Local parameters setting #############  \n",
    "    \n",
    "     # Get the ppi of the selected prime display\n",
    "    ppi = DISPLAYS[prime_disp]['ppi']\n",
    "    \n",
    "     # Check the number of frames and buttons\n",
    "    frames_nb = len(titles) -1 \n",
    "    buttons_nb = len(buttons_labels)\n",
    "    if frames_nb!=1 or buttons_nb!=2:\n",
    "        print('Number of titles:', len(titles) )\n",
    "        print('Number of buttons:', len(button_labels) )\n",
    "        print('The number of titles should be 2 and the number of buttons should be 2')\n",
    "    \n",
    "     # Set the ratio of frames-width to the titles-max-width\n",
    "    frame_ratio = widget_ratio\n",
    "    \n",
    "     # Set the ration of window-width to the frame-width\n",
    "    win_ratio = widget_ratio \n",
    "    \n",
    "     # Set the buttons-height to the label-height ratio to vertically center the label in the button\n",
    "    button_ratio = 2.5\n",
    "    \n",
    "     # Set a potential ratio for correcting the conversion of mm to px for the buttons sizes\n",
    "     # Todo: adapt these ratios to correct the discrepancy between the set mm sizes \n",
    "     # and the effective mm sizes on the screen for MacOs \n",
    "     # (correction still to be understood)\n",
    "    buttonsize_mmtopx_ratios = (1,1,1)\n",
    "    \n",
    "     # Set the value in mm for the correction of the sizes in milimeters \n",
    "     # before use for computing the widgets horizontal positions in pixels \n",
    "     # (correction still to be understood)\n",
    "    mm_size_corr = 1\n",
    "    \n",
    "     # Set the maximum lines number for editing the selected folder name\n",
    "    max_lines_nb = 3 \n",
    "    \n",
    "    ############# Tkinter window management #############\n",
    "    \n",
    "     # Create the tk window\n",
    "    win = tk.Tk()\n",
    "    win.attributes(\"-topmost\", True)\n",
    "    win.title(titles['main']) \n",
    "    \n",
    "     # Set the fonts to be used\n",
    "    frame_font = TkFont.Font(family='arial', size=16, weight='bold')\n",
    "    text_font = TkFont.Font(family='arial', size=12, weight='normal')\n",
    "    button_font = TkFont.Font(family='arial', size=12, weight='normal')\n",
    "    \n",
    "     # Computes the maximum size in mm of the list of titles\n",
    "    titles_mm_max = _str_max_len_mm(titles.values(), frame_font, ppi)\n",
    "    \n",
    "     # Computes button sizes in mm and pixels using button label sizes and button_ratio\n",
    "     # Buttons width is the button heigth added to the labels width to horizontally center the label in the button \n",
    "    labels_widthmm = [_str_size_mm(buttons_labels[i],button_font, ppi)[0] for i in range(buttons_nb)]\n",
    "    label_heightmm = _str_size_mm(buttons_labels[0],button_font, ppi)[1]\n",
    "    button_heightmm =  label_heightmm * button_ratio\n",
    "    buttons_widthmm = (labels_widthmm[0] + button_heightmm, labels_widthmm[1] + button_heightmm)\n",
    "    buttons_widthpx = (_mm_to_px(buttons_widthmm[0],ppi,buttonsize_mmtopx_ratios[0]), \n",
    "                       _mm_to_px(buttons_widthmm[1],ppi,buttonsize_mmtopx_ratios[1]))\n",
    "    button_heigthpx = _mm_to_px(button_heightmm,ppi,buttonsize_mmtopx_ratios[2])\n",
    "\n",
    "     # Computes the frame width in pixels from titles maximum size in mm using frame_ratio\n",
    "    frame_widthmm = titles_mm_max * frame_ratio    \n",
    "    frame_widthpx = str(_mm_to_px(frame_widthmm,ppi))\n",
    "\n",
    "     # Computes the window width in pixels from the frame width and buttons width using win_ratio\n",
    "    win_widthmm = max(frame_widthmm,sum(buttons_widthmm)) * win_ratio \n",
    "    win_widthpx = str(_mm_to_px(win_widthmm,ppi))\n",
    "\n",
    "     # Computes the buttons horizontal positions in pixels \n",
    "     # assuming 2 buttons and with correction of size in mm by mm_size_corr value\n",
    "    padx_ratio = buttons_nb * 2  \n",
    "    pad_xmm = (win_widthmm - min(frame_widthmm,sum(buttons_widthmm))) / padx_ratio\n",
    "    buttons_xmm = (pad_xmm, buttons_widthmm[0] + 3 * pad_xmm)\n",
    "    buttons_xpx = (_mm_to_px(buttons_xmm[0] - mm_size_corr,ppi), _mm_to_px(buttons_xmm[1] - mm_size_corr,ppi))\n",
    "\n",
    "     # Computes the frames heigth unit\n",
    "    _, text_heigthmm = _str_size_mm('Users/',text_font, ppi)\n",
    "    frame_unit_heightmm = min(button_heightmm,text_heigthmm) \n",
    "    print('frame_unit_heightmm:',frame_unit_heightmm)\n",
    "\n",
    "     # Computes the buttons vertical position in pixels\n",
    "    button_ymm = frame_unit_heightmm \n",
    "    print('buttons y pos:',button_ymm)\n",
    "    button_ypx = _mm_to_px(button_ymm,ppi)\n",
    "\n",
    "     # Computes the frame heigth in mm and in pixels \n",
    "    pads_nb = 4  # 2 frame units above and 2 frame units under the edited text \n",
    "    max_frame_unit_nb = pads_nb + max_lines_nb  \n",
    "    frame_heightmm = frame_unit_heightmm * max_frame_unit_nb\n",
    "    print('frame_heightmm:', frame_heightmm)\n",
    "    frame_heightpx = str(_mm_to_px(frame_heightmm,ppi))\n",
    "\n",
    "     # Computes the frame positions in pixels\n",
    "    frame_xmm = (win_widthmm - frame_widthmm) / 2\n",
    "    frame_ymm = button_ymm + button_heightmm + 2 * frame_unit_heightmm\n",
    "    print('frames x pos:',frame_xmm)\n",
    "    print('frames y pos:',frame_ymm)\n",
    "    frame_xpx, frame_ypx = _mm_to_px(frame_xmm,ppi), _mm_to_px(frame_ymm,ppi)\n",
    "\n",
    "    # Computes the window heigth in mm and in pixels \n",
    "    # with frame_unit_heightmm separating vertically the widgets\n",
    "    win_heightmm = button_ymm + button_heightmm + frame_heightmm + 3 * frame_unit_heightmm\n",
    "    print('win_heightmm:',win_heightmm)\n",
    "    win_heightpx = str(_mm_to_px(win_heightmm,ppi))\n",
    "\n",
    "     # Set the window geometry\n",
    "    win_xpx = str(int(DISPLAYS[prime_disp]['x']) + 50)\n",
    "    win_ypx = str(int(DISPLAYS[prime_disp]['y']) + 50)\n",
    "    win.geometry(f'{win_widthpx}x{win_heightpx}+{win_xpx}+{win_ypx}')\n",
    "    #win.resizable(0, 0)\n",
    "\n",
    "     # Create the folder result frame and set its geometry \n",
    "    folder_result = tk.LabelFrame(master=win,              \n",
    "                text=titles['result'],\n",
    "                font=frame_font)\n",
    "    folder_result.place(x=frame_xpx,\n",
    "                    y=frame_ypx,\n",
    "                    width=frame_widthpx,\n",
    "                    height=frame_heightpx)\n",
    "\n",
    "     # Create the button for folder selection\n",
    "    select_button = tk.Button(win,\n",
    "                          text=buttons_labels[0],\n",
    "                          font=button_font,\n",
    "                          command=outdir_folder_choice)\n",
    "    select_button.place(x=buttons_xpx[0], \n",
    "                    y=button_ypx, \n",
    "                    width=buttons_widthpx[0], \n",
    "                    height=button_heigthpx)\n",
    "\n",
    "     # Create the help button\n",
    "    help_button = tk.Button(win,\n",
    "                        text=buttons_labels[1],\n",
    "                        font=button_font,\n",
    "                        command=help)\n",
    "    help_button.place(x=buttons_xpx[1], \n",
    "                  y=button_ypx, \n",
    "                  width=buttons_widthpx[1], \n",
    "                  height=button_heigthpx)\n",
    "\n",
    "    win.mainloop()\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Select_multi_items(list_item,mode = 'multiple'): \n",
    "\n",
    "    \"\"\"interactive selection of items among the list list_item\n",
    "    \n",
    "    Args:\n",
    "        list_item (list): list of items used for the selection\n",
    "        \n",
    "    Returns:\n",
    "        val (list): list of selected items without duplicate\n",
    "        \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import tkinter as tk\n",
    "    \n",
    "    global val\n",
    "\n",
    "    window = tk.Tk()\n",
    "    window.geometry(GEOMETRY_FILTERS_SELECTION)\n",
    "    window.attributes(\"-topmost\", True)\n",
    "    if mode == 'single': \n",
    "        title = 'Single item selection'\n",
    "    else:\n",
    "        title = 'Multiple items selection'\n",
    "    window.title(title)\n",
    "\n",
    "    yscrollbar = tk.Scrollbar(window)\n",
    "    yscrollbar.pack(side = tk.RIGHT, fill = tk.Y)\n",
    "    selectmode = tk.MULTIPLE\n",
    "    if mode == 'single':selectmode = tk.SINGLE\n",
    "    listbox = tk.Listbox(window, width=40, height=10, selectmode=selectmode,\n",
    "                     yscrollcommand = yscrollbar.set)\n",
    "\n",
    "    x = list_item\n",
    "    for idx,item in enumerate(x):\n",
    "        listbox.insert(idx, item)\n",
    "        listbox.itemconfig(idx,\n",
    "                           bg = \"white\" if idx % 2 == 0 else \"white\")\n",
    "    \n",
    "    def selected_item():\n",
    "        global val\n",
    "        val = [listbox.get(i) for i in listbox.curselection()]\n",
    "        if os.name == 'nt':\n",
    "            window.destroy()\n",
    "\n",
    "    btn = tk.Button(window, text='OK', command=selected_item)\n",
    "    btn.pack(side='bottom')\n",
    "\n",
    "    listbox.pack(padx = 10, pady = 10,expand = tk.YES, fill = \"both\")\n",
    "    yscrollbar.config(command = listbox.yview)\n",
    "    window.mainloop()\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gui_params(titles, buttons_labels, fonts, mm_size_corr, gui_disp=0): \n",
    "\n",
    "\n",
    "    # Local imports\n",
    "    #from .BiblioSys import DISPLAYS\n",
    "    #from .BiblioGeneralGlobals import IN_TO_MM\n",
    "    #from .BiblioSpecificGlobals import GUI_BUTTON_RATIO, GUI_TEXT_MAX_LINES_NB, GUI_WIDGET_RATIO\n",
    "    \n",
    "    IN_TO_MM = bau.IN_TO_MM\n",
    "    DISPLAYS = bau.DISPLAYS\n",
    "    GUI_BUTTON_RATIO = bau.GUI_BUTTON_RATIO\n",
    "    GUI_TEXT_MAX_LINES_NB = bau.GUI_TEXT_MAX_LINES_NB\n",
    "    GUI_WIDGET_RATIO = bau.GUI_WIDGET_RATIO\n",
    "    \n",
    "    ############# Local parameters setting ############# \n",
    "\n",
    "    # Getting the ppi of the selected prime display.\n",
    "    ppi = DISPLAYS[prime_disp]['ppi']\n",
    "    \n",
    "    # Checking the number of frames and buttons.\n",
    "    frames_nb = len(titles) - 1 \n",
    "    buttons_nb = len(buttons_labels)\n",
    "    if frames_nb!=1 or buttons_nb!=2:\n",
    "        print('Number of titles:', len(titles) )\n",
    "        print('Number of buttons:', len(button_labels) )\n",
    "        print('The number of titles should be 2 \\\n",
    "               and the number of buttons should be 2.\\\n",
    "               Please define ad hoc number of widgets.')\n",
    "        \n",
    "    # Setting geometry parameters of gui widgets\n",
    "    if widget_ratio==None: widget_ratio = GUI_WIDGET_RATIO\n",
    "    if button_ratio==None: button_ratio = GUI_BUTTON_RATIO\n",
    "    if max_lines_nb==None: max_lines_nb = GUI_TEXT_MAX_LINES_NB                \n",
    "    \n",
    "    # Setting the ratio of frames-width to the titles-max-width.\n",
    "    frame_ratio = widget_ratio\n",
    "    \n",
    "    # Setting the ratio of window-width to the frame-width.\n",
    "    win_ratio = widget_ratio \n",
    "    \n",
    "    # Setting a potential ratio for correcting the conversion from mm to px for the buttons sizes.\n",
    "    # Todo: adapt these ratios to correct the discrepancy between the set mm sizes \n",
    "    # and the effective mm sizes on the screen for MacOs \n",
    "    # (correction still to be understood).\n",
    "    buttonsize_mmtopx_ratios = (1,1,1)\n",
    "    \n",
    "    # Setting the value in mm for the correction of the sizes in milimeters \n",
    "    # before use for computing the widgets horizontal positions in pixels \n",
    "    # (correction still to be understood).\n",
    "    mm_size_corr = 1\n",
    "\n",
    "    # Computing the maximum size in mm of the list of titles.\n",
    "    titles_mm_max = _str_max_len_mm(titles.values(), fonts['frame'], ppi)\n",
    "    \n",
    "    # Computing button sizes in mm and pixels using button label sizes and button_ratio.\n",
    "    # Buttons width is the button heigth added to the labels width \n",
    "    # to horizontally center the label in the button. \n",
    "    labels_widthmm = [_str_size_mm(buttons_labels[i],fonts['button'], ppi)[0] for i in range(buttons_nb)]\n",
    "    label_heightmm = _str_size_mm(buttons_labels[0],fonts['button'], ppi)[1]\n",
    "    button_heightmm =  label_heightmm * button_ratio\n",
    "    buttons_widthmm = (labels_widthmm[0] + button_heightmm, labels_widthmm[1] + button_heightmm)\n",
    "    buttons_widthpx = (_mm_to_px(buttons_widthmm[0],ppi,buttonsize_mmtopx_ratios[0]), \n",
    "                       _mm_to_px(buttons_widthmm[1],ppi,buttonsize_mmtopx_ratios[1]))\n",
    "    button_heigthpx = _mm_to_px(button_heightmm,ppi,buttonsize_mmtopx_ratios[2])\n",
    "\n",
    "    # Computing the frame width in pixels from titles maximum size in mm using frame_ratio.\n",
    "    frame_widthmm = titles_mm_max * frame_ratio    \n",
    "    frame_widthpx = str(_mm_to_px(frame_widthmm,ppi))\n",
    "\n",
    "    # Computing the window width in pixels from the frame width and buttons width using win_ratio.\n",
    "    win_widthmm = max(frame_widthmm,sum(buttons_widthmm)) * win_ratio \n",
    "    win_widthpx = str(_mm_to_px(win_widthmm,ppi))\n",
    "\n",
    "     # Computing the buttons horizontal positions in pixels \n",
    "     # assuming 2 buttons and with correction of size in mm by mm_size_corr value.\n",
    "    padx_ratio = buttons_nb * 2  \n",
    "    pad_xmm = (win_widthmm - min(frame_widthmm,sum(buttons_widthmm))) / padx_ratio\n",
    "    buttons_xmm = (pad_xmm, buttons_widthmm[0] + 3 * pad_xmm)\n",
    "    buttons_xpx = (_mm_to_px(buttons_xmm[0] - mm_size_corr,ppi), _mm_to_px(buttons_xmm[1] - mm_size_corr,ppi))\n",
    "\n",
    "    # Computing the frames heigth unit.\n",
    "    _, text_heigthmm = _str_size_mm('Users/',fonts['text'], ppi)\n",
    "    frame_unit_heightmm = min(button_heightmm,text_heigthmm) \n",
    "\n",
    "    # Computing the buttons vertical position in pixels.\n",
    "    button_ymm = frame_unit_heightmm \n",
    "    button_ypx = _mm_to_px(button_ymm,ppi)\n",
    "\n",
    "    # Computing the frame heigth in mm and in pixels.\n",
    "    pads_nb = 4  # 2 frame units above and 2 frame units under the edited text. \n",
    "    max_frame_unit_nb = pads_nb + max_lines_nb  \n",
    "    frame_heightmm = frame_unit_heightmm * max_frame_unit_nb\n",
    "    frame_heightpx = str(_mm_to_px(frame_heightmm,ppi))\n",
    "\n",
    "    # Computing the frame positions in pixels.\n",
    "    frame_xmm = (win_widthmm - frame_widthmm) / 2\n",
    "    frame_ymm = button_ymm + button_heightmm + 2 * frame_unit_heightmm\n",
    "    frame_xpx, frame_ypx = _mm_to_px(frame_xmm,ppi), _mm_to_px(frame_ymm,ppi)\n",
    "\n",
    "    # Computing the window heigth in mm and in pixels .\n",
    "    # with frame_unit_heightmm separating vertically the widgets.\n",
    "    win_heightmm = button_ymm + button_heightmm + frame_heightmm + 3 * frame_unit_heightmm\n",
    "    win_heightpx = str(_mm_to_px(win_heightmm,ppi))\n",
    "\n",
    "    # Setting the window geometry.\n",
    "    win_xpx = str(int(DISPLAYS[gui_disp]['x']) + 50)\n",
    "    win_ypx = str(int(DISPLAYS[gui_disp]['y']) + 50)\n",
    "    \n",
    "    return  ppi, buttons_widthpx, button_heigthpx, buttons_xpx, button_ypx, frame_widthpx, frame_heightpx, frame_xpx, frame_ypx,  win_widthpx, win_heightpx, win_xpx, win_ypx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "user_root = Path.home()\n",
    "\n",
    "## Set the parameters of the folder-selection GUI\n",
    "\n",
    " # Set the widget ratio to set the window size\n",
    "gui_widget_ratio = 1.2\n",
    "\n",
    " # Set the GUI display\n",
    "gui_disp = [i for i in range(len(bau.DISPLAYS)) if bau.DISPLAYS[i]['is_primary']][0]\n",
    "   # Get the prime display choice\n",
    "   # TO DO: replace input by a GUI to select the activ_display\n",
    "disp_select = input('Select Id of gui prime-display '+\n",
    "                   '(value: 0 to '+ str(len(bau.DISPLAYS)-1)+\n",
    "                  '; default:'+ str(gui_disp)+')')\n",
    "if disp_select: gui_disp = int(disp_select)   \n",
    "\n",
    " # Setting the GUI titles\n",
    "gui_titles = {'main':   'Folder selection window',\n",
    "              'result': 'Selected folder'}\n",
    "gui_buttons = ['SELECTION','HELP']\n",
    "\n",
    " # Getting the corpuses folder\n",
    "corpuses_folder = bau.select_folder_gui_new(user_root, gui_titles, gui_buttons, gui_disp)\n",
    "print('Corpuses folder:', corpuses_folder)\n",
    "\n",
    "#########################################################\n",
    "## Selection of corpus file\n",
    "\n",
    " # Setting the widget ratio to set the window size\n",
    "gui_widget_ratio = 1.2\n",
    "\n",
    " # Setting the GUI titles\n",
    "gui_titles = {'main':   'File selection window',\n",
    "              'result': 'Selected file'}\n",
    "\n",
    "corpusfiles_list = os.listdir(corpuses_folder)\n",
    "corpusfiles_list.sort()\n",
    "print('Please select the corpus via the tk window')\n",
    "GEOMETRY_FILTERS_SELECTION = '500x580+50+50'\n",
    "#myprojectname = bau.Select_multi_items(corpusfiles_list,'single')[0]+'/'\n",
    "myprojectname = select_multi_items_gui(corpusfiles_list, corpuses_folder, gui_titles, mode = 'single', gui_disp, gui_widget_ratio)\n",
    "project_folder = corpuses_folder /Path(myprojectname)\n",
    "print(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test parsing\n",
    "## TO DO: \n",
    "- vérifier l'impact des noms de colonnes sur le reste du package\n",
    "- vérifier l'usage du package en push-pull : ne plus travailler en séquentiel mais en parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import Template\n",
    "\n",
    "    \n",
    "    \n",
    "t = Template('$colname in @$item') # Template for the query\n",
    "\n",
    "df = pd.read_csv(out_dir_parsing / Path(bau.DIC_OUTDIR_PARSING['A']),\n",
    "                 sep='\\t',\n",
    "                 dtype={x : 'str' for x in bau.COL_NAMES['articles'][1:]})\n",
    "\n",
    "\n",
    "year =['0']\n",
    "query = t.substitute({'colname':df.columns[2],\n",
    "                      'item':'year'})\n",
    "set(df.query(query)[df.columns[0]]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_articles_wos(df_corpus):\n",
    " \n",
    "    '''Builds the dataframe \"df_article\" with ten columns:\n",
    "   \n",
    "    Authors|Year|Source title|Volume|Page start|DOI|Document Type|\n",
    "    Language of Original Document|Title|EID\n",
    " \n",
    "    Args:\n",
    "        df_corpus (dataframe): the dataframe of the wos corpus\n",
    " \n",
    " \n",
    "    Returns:\n",
    "        The dataframe df_institution\n",
    "        \n",
    "    '''\n",
    "    # Local imports\n",
    "    import BiblioAnalysis_Utils as bau\n",
    "    \n",
    "    # Local imports\n",
    "    #from .BiblioParsingUtils import name_normalizer\n",
    "    #from .BiblioSpecificGlobals import COL_NAMES\n",
    "    #from .BiblioSpecificGlobals import COLUMN_LABEL_WOS    \n",
    "\n",
    "    def str_int_convertor(x):\n",
    "        if x:\n",
    "            return(str(x))\n",
    "        else:\n",
    "            print('0')\n",
    "            return '0'\n",
    "    \n",
    "    def treat_author(list_authors):\n",
    "        first_author = list_authors.split(';')[0] # we pick the first author\n",
    "        return  bau.name_normalizer(first_author)\n",
    "    \n",
    "    pub_id_alias = bau.COL_NAMES['articles'][0]\n",
    "    author_alias = bau.COL_NAMES['articles'][1]\n",
    "    year_alias = bau.COL_NAMES['articles'][2]\n",
    "\n",
    "    wos_columns = [bau.COLUMN_LABEL_WOS['authors'],\n",
    "                   bau.COLUMN_LABEL_WOS['year'],\n",
    "                   bau.COLUMN_LABEL_WOS['journal'], \n",
    "                   bau.COLUMN_LABEL_WOS['volume'],\n",
    "                   bau.COLUMN_LABEL_WOS['page_start'],\n",
    "                   bau.COLUMN_LABEL_WOS['doi'],\n",
    "                   bau.COLUMN_LABEL_WOS['document_type'],\n",
    "                   bau.COLUMN_LABEL_WOS['language'],\n",
    "                   bau.COLUMN_LABEL_WOS['title'],\n",
    "                   bau.COLUMN_LABEL_WOS['issn']]\n",
    "                   \n",
    "    df_article = df_corpus.loc[:,wos_columns].astype(str)\n",
    "\n",
    "    df_article.rename (columns = dict(zip(wos_columns,bau.COL_NAMES['articles'][1:])),\n",
    "                       inplace = True)    \n",
    "                                                                                                \n",
    "    df_article[author_alias] = df_article[author_alias].apply(treat_author) \n",
    "   \n",
    "    df_article[year_alias] = df_article[year_alias].apply(str_int_convertor)\n",
    "    \n",
    "    df_article.insert(0, pub_id_alias, list(df_corpus.index))\n",
    "   \n",
    "    return df_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BiblioAnalysis_Utils as bau\n",
    "df = bau.read_database_wos(r'C:\\Users\\franc\\BiblioAnalysis_Files\\LITEN\\rawdata\\savedrecs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = 'A'   # Deals with articles\n",
    "df_A = _build_articles_wos(df)\n",
    "df_A.to_csv(Path(out_dir_parsing) / Path(bau.DIC_OUTDIR_PARSING[item]),\n",
    "            index=False,\n",
    "            sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgrade_col_names(corpuses_folder):\n",
    "    \n",
    "    '''Add names to the colummn of the parsing and filter_<i> files to take into account the\n",
    "    upgrage of BiblioAnalysis_Utils.\n",
    "    \n",
    "    Args:\n",
    "        corpuses_folder (str): folder containing all the corpuses\n",
    "    '''\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    COL_NAMES = bau.COL_NAMES\n",
    "    \n",
    "    # Beware: the new file authorsinst.dat is not present in the Iona's parsing folders\n",
    "    dict_filename_conversion  = {'addresses.dat':'address',\n",
    "                                'articles.dat': 'articles',\n",
    "                                'authors.dat':'authors',\n",
    "                                'authorsinst.dat':'auth_inst',\n",
    "                                'authorskeywords.dat':'authorskeywords',\n",
    "                                'countries.dat':'country',\n",
    "                                'institutions.dat':'institution',\n",
    "                                'journalkeywords.dat':'journalkeywords',\n",
    "                                'keywords.dat':'keywords',\n",
    "                                'references.dat':'references',\n",
    "                                'subjects.dat': 'subject',\n",
    "                                'subjects2.dat':'sub_subject',\n",
    "                                'titlekeywords.dat':'titlekeywords'}\n",
    "\n",
    "    new_cols ={ 'authorskeywords.dat': ['Pub_id','Keyword'] ,\n",
    "                'journalkeywords.dat': ['Pub_id','Keyword'] ,\n",
    "                'titlekeywords.dat': ['Pub_id','Keyword']}\n",
    "\n",
    "    dict_filename_conversion = {**dict_filename_conversion , **new_cols} # to be replace by dict_filename_conversion | new_cols\n",
    "                                                                         # with python 3.9\n",
    "\n",
    "    for dirpath, dirs, files in os.walk(corpuses_folder):  \n",
    "        if ('parsing' in   dirpath) |  ('filter_' in  dirpath):\n",
    "            for file in  [file for file in files if (file.split('.')[1]=='dat') and (file != 'database.dat')]:\n",
    "                try:\n",
    "                    print(file, COL_NAMES[dict_filename_conversion[file]],os.path.join(dirpath,file))\n",
    "                    df = pd.read_csv(os.path.join(dirpath,file),sep='\\t',header=None)\n",
    "                    df.columns = COL_NAMES[dict_filename_conversion[file]]\n",
    "                    pd.to_csv(os.path.join(dirpath,file),sep='\\t')\n",
    "\n",
    "                except:\n",
    "                    print('ERROR ',file)\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
